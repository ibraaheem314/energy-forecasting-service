# âš¡ Energy Forecasting - Projet Data Science

**PrÃ©vision de consommation Ã©nergÃ©tique avec Machine Learning**

> Projet junior Data Science pour la prÃ©vision de consommation Ã©nergÃ©tique utilisant les donnÃ©es RTE et des techniques de ML.

## ğŸ“‹ Table des matiÃ¨res

- [ğŸ¯ Objectifs](#-objectifs)
- [ğŸ”§ Structure du projet](#-structure-du-projet)
- [ğŸš€ DÃ©marrage rapide](#-dÃ©marrage-rapide)
- [ğŸ“Š DonnÃ©es](#-donnÃ©es)
- [ğŸ¤– ModÃ¨les](#-modÃ¨les)
- [ğŸ“ˆ RÃ©sultats](#-rÃ©sultats)
- [ğŸ§ª Utilisation](#-utilisation)

## ğŸ¯ Objectifs

Ce projet Data Science implÃ©mente un systÃ¨me de **prÃ©vision de consommation Ã©nergÃ©tique** pour anticiper la demande sur les prochains jours.

**Objectifs pÃ©dagogiques :**
- **Analyse exploratoire** des donnÃ©es Ã©nergÃ©tiques
- **Feature engineering** pour les sÃ©ries temporelles
- **ModÃ©lisation ML** avec diffÃ©rents algorithmes
- **Ã‰valuation** et comparaison des performances
- **API simple** pour servir les prÃ©dictions
- **Dashboard** de visualisation des rÃ©sultats

## ğŸ”§ Structure du projet

```
energy-forecasting/
â”œâ”€ app/                          # Application
â”‚  â”œâ”€ api/                       # API FastAPI
â”‚  â”‚  â”œâ”€ main.py                 # Endpoints
â”‚  â”‚  â””â”€ schemas.py              # ModÃ¨les de donnÃ©es
â”‚  â”œâ”€ services/                  # Services ML
â”‚  â”‚  â”œâ”€ loader.py               # Chargement donnÃ©es
â”‚  â”‚  â”œâ”€ features.py             # Feature engineering
â”‚  â”‚  â””â”€ models.py               # ModÃ¨les ML
â”‚  â””â”€ config.py                  # Configuration
â”œâ”€ scripts/                      # Scripts d'entraÃ®nement
â”‚  â”œâ”€ train_models.py            # EntraÃ®nement
â”‚  â””â”€ evaluate_models.py         # Ã‰valuation
â”œâ”€ notebooks/                    # Notebooks Jupyter
â”‚  â””â”€ 01_exploration_donnees.ipynb
â”œâ”€ dashboard/                    # Dashboard Streamlit
â”‚  â””â”€ app.py                     # Visualisations
â”œâ”€ jobs/                         # Jobs de donnÃ©es
â”‚  â””â”€ fetch_data.py              # RÃ©cupÃ©ration
â”œâ”€ tests/                        # Tests
â”œâ”€ data/                         # DonnÃ©es (gitignored)
â”œâ”€ models/                       # ModÃ¨les sauvegardÃ©s
â””â”€ README.md
```

## ğŸš€ DÃ©marrage rapide

### PrÃ©requis

- Python 3.9+
- Docker & Docker Compose
- Git

### Installation

1. **Cloner le repository**
```bash
git clone https://github.com/your-username/energy-forecasting-service.git
cd energy-forecasting-service
```

2. **DÃ©marrage avec Docker (recommandÃ©)**
```bash
# DÃ©marrage complet avec une seule commande
make quick-start

# Ou manuellement
docker-compose up -d
```

3. **Installation locale pour dÃ©veloppement**
```bash
# CrÃ©er l'environnement virtuel
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Installer les dÃ©pendances
make install-dev

# Configurer l'environnement
make setup-env
# Ã‰diter le fichier .env avec vos paramÃ¨tres
```

### Services disponibles

AprÃ¨s le dÃ©marrage, les services suivants sont accessibles :

- ğŸ“Š **Dashboard** : http://localhost:8501
- ğŸ”Œ **API** : http://localhost:8000 (docs: /docs)
- ğŸ“ˆ **MLflow** : http://localhost:5000
- ğŸ’¾ **Database** : localhost:5432
- ğŸ“‰ **Grafana** : http://localhost:3000
- ğŸ” **Prometheus** : http://localhost:9090

## ğŸ“Š Sources de donnÃ©es

### DonnÃ©es RTE (RÃ©seau de Transport d'Ã‰lectricitÃ©)

Le service utilise les APIs ouvertes RTE pour rÃ©cupÃ©rer :

- **Consommation rÃ©alisÃ©e** par rÃ©gion
- **Production par filiÃ¨re** (nuclÃ©aire, Ã©olien, solaire, etc.)
- **DonnÃ©es de marchÃ©** (prix spot, capacitÃ©s)
- **PrÃ©visions mÃ©tÃ©orologiques** impactant la consommation

```bash
# Configuration RTE dans .env
RTE_API_KEY=your-rte-api-key
RTE_API_BASE_URL=https://digital.iservices.rte-france.com
```

### Sources complÃ©mentaires

- **MÃ©tÃ©o** : OpenWeatherMap API
- **Jours fÃ©riÃ©s** : Algorithme de calcul franÃ§ais
- **Indicateurs Ã©conomiques** : IntÃ©gration optionnelle

### RÃ©cupÃ©ration des donnÃ©es

```bash
# RÃ©cupÃ©ration manuelle
make fetch-data

# RÃ©cupÃ©ration automatique (configurÃ©e dans docker-compose)
# Toutes les 6 heures via le scheduler
```

## ğŸ¤– ModÃ¨les implÃ©mentÃ©s

### ModÃ¨les de sÃ©ries temporelles

1. **ARIMA** : ModÃ¨le statistique classique
   - Auto-dÃ©tection des paramÃ¨tres (p,d,q)
   - Gestion de la saisonnalitÃ©

2. **Prophet** : DÃ©veloppÃ© par Facebook
   - Robuste aux valeurs manquantes
   - ModÃ©lisation des jours fÃ©riÃ©s
   - Tendances non-linÃ©aires

3. **Ensemble Methods**
   - Random Forest Regressor
   - Gradient Boosting
   - XGBoost avec optimisation bayÃ©sienne

4. **Deep Learning** (optionnel)
   - LSTM networks
   - Transformer architecture
   - Conv1D pour patterns locaux

### Feature Engineering

- **Features temporelles** : heure, jour, mois, saison
- **Features cycliques** : encodage sinusoÃ¯dal
- **Lags** : valeurs historiques (1h Ã  7 jours)
- **Rolling statistics** : moyennes mobiles, Ã©carts-types
- **Features mÃ©tÃ©o** : tempÃ©rature, humiditÃ©, vent
- **Features calendaires** : weekends, jours fÃ©riÃ©s

### EntraÃ®nement et Ã©valuation

```bash
# EntraÃ®nement de tous les modÃ¨les
make train-models

# Backtest sur donnÃ©es historiques
make backtest

# Ã‰valuation comparÃ©e
python -m app.services.evaluate compare-models
```

## ğŸ“ˆ Dashboard et visualisations

Le dashboard Streamlit fournit :

### ğŸ“Š Vues principales

1. **Forecasts** : PrÃ©dictions avec intervalles de confiance
2. **Model Performance** : Comparaison des mÃ©triques (MAE, MAPE, RÂ²)
3. **Historical Data** : Analyse des donnÃ©es historiques
4. **Settings** : Gestion des modÃ¨les et configuration

### ğŸ¯ MÃ©triques business

- **PrÃ©cision de prÃ©vision** : MAPE < 5% sur 24h
- **FiabilitÃ©** : RÂ² > 0.90 pour les modÃ¨les principaux
- **Latence** : PrÃ©dictions < 1s pour 24h ahead
- **Couverture** : Intervalles de confiance Ã  95%

### ğŸ–¼ï¸ Visualisations

- **SÃ©ries temporelles** interactives (Plotly)
- **Heatmaps** de corrÃ©lation
- **Distributions** des erreurs de prÃ©diction
- **Feature importance** par modÃ¨le
- **Monitoring** temps rÃ©el des performances

## ğŸ”„ Pipeline MLOps

### Workflow automatisÃ©

1. **Data Pipeline**
   ```
   Fetch Data â†’ Validation â†’ Feature Engineering â†’ Storage
   ```

2. **Model Pipeline**
   ```
   Training â†’ Validation â†’ Registry â†’ A/B Testing â†’ Deployment
   ```

3. **Monitoring Pipeline**
   ```
   Predictions â†’ Metrics â†’ Alerts â†’ Retraining Triggers
   ```

### CI/CD avec GitHub Actions

- **Tests automatisÃ©s** : Unitaires, intÃ©gration, performance
- **Quality Gates** : Linting, sÃ©curitÃ©, couverture
- **DÃ©ploiement** : Staging automatique, production manuelle
- **Monitoring** : Alertes Slack, mÃ©triques Prometheus

### MLflow Integration

- **Experiment Tracking** : HyperparamÃ¨tres, mÃ©triques, artifacts
- **Model Registry** : Versioning, staging, production
- **Model Serving** : DÃ©ploiement via REST API
- **Lineage** : TraÃ§abilitÃ© complÃ¨te des modÃ¨les

## ğŸ“š Documentation

### API Documentation

- **FastAPI Docs** : http://localhost:8000/docs
- **ReDoc** : http://localhost:8000/redoc
- **OpenAPI Spec** : http://localhost:8000/openapi.json

### Code Documentation

```bash
# GÃ©nÃ©rer la documentation
make docs

# Servir localement
make docs-serve  # http://localhost:8080
```

### Exemples d'usage

```python
# Client API Python
import requests

# PrÃ©diction sur 24h
response = requests.post("http://localhost:8000/forecast", json={
    "location": "region_1",
    "start_time": "2024-01-15T00:00:00",
    "end_time": "2024-01-16T00:00:00",
    "forecast_type": "consumption",
    "confidence_interval": True
})

predictions = response.json()["predictions"]
```

```bash
# Client cURL
curl -X POST "http://localhost:8000/forecast" \
  -H "Content-Type: application/json" \
  -d '{
    "location": "region_1",
    "start_time": "2024-01-15T00:00:00",
    "end_time": "2024-01-16T00:00:00",
    "forecast_type": "consumption"
  }'
```

## ğŸ§ª Tests

### Types de tests

```bash
# Tests unitaires
make test

# Tests rapides (sans couverture)
make test-fast

# Tests d'intÃ©gration
make test-integration

# Tests de performance
make benchmark

# Tests de charge
make load-test
```

### Couverture de code

- **Cible** : >80% de couverture
- **Reports** : HTML, XML, terminal
- **CI/CD** : Blocage si < 80%

### StratÃ©gie de tests

- **Unit Tests** : Logique mÃ©tier, feature engineering
- **Integration Tests** : API endpoints, database
- **E2E Tests** : Workflow complet forecast
- **Performance Tests** : Latence, throughput
- **Security Tests** : VulnÃ©rabilitÃ©s, injections

## ğŸš¢ DÃ©ploiement

### Environnements

1. **Development** : Docker Compose local
2. **Staging** : Kubernetes (auto-deploy depuis `develop`)
3. **Production** : Kubernetes (deploy manuel depuis `main`)

### Configuration par environnement

```bash
# Development
cp .env.example .env.dev
# Edit with dev settings

# Production
cp .env.example .env.prod
# Edit with production settings
```

### Commandes de dÃ©ploiement

```bash
# Staging
make deploy-staging

# Production
make deploy-prod

# Rollback
kubectl rollout undo deployment/energy-forecasting-api
```

### Health Checks

- **API** : `/health` endpoint
- **Database** : Connection pooling
- **Redis** : Cache availability
- **MLflow** : Model registry access

## ğŸ† Livrables Portfolio

Ce projet fournit des livrables concrets pour votre CV/Portfolio :

### ğŸ“Š Rapport Comparatif des ModÃ¨les

- **Benchmark** sur donnÃ©es RTE rÃ©elles
- **MÃ©triques** : MAE, MAPE, RÂ², directional accuracy
- **Analyse** des forces/faiblesses par modÃ¨le
- **Recommandations** business

### ğŸ“ˆ Dashboard Interactif

- **DÃ©mo live** : PrÃ©dictions temps rÃ©el
- **Visualisations** professionnelles
- **UX/UI** moderne avec Streamlit
- **Responsive** design

### ğŸ”§ Architecture Technique

- **Microservices** avec Docker
- **API REST** documentÃ©e
- **CI/CD** avec GitHub Actions
- **MLOps** avec MLflow

### ğŸ’¼ Use Case Business

- **Optimisation** de la production Ã©nergÃ©tique
- **Anticipation** des pics de consommation
- **Gestion** des risques pour assureurs
- **Smart Grid** applications

### ğŸ“ Documentation Technique

- **README** complet avec guides
- **Architecture** diagrammes
- **API** documentation
- **Deployment** guides

## ğŸ¤ Contribution

Contributions welcomes ! Voir [CONTRIBUTING.md](CONTRIBUTING.md) pour les guidelines.

## ğŸ“„ License

MIT License - voir [LICENSE](LICENSE) pour dÃ©tails.

## ğŸ“ Contact

- **Email** : team@energy-forecasting.com
- **Issues** : [GitHub Issues](https://github.com/your-username/energy-forecasting-service/issues)
- **Discussions** : [GitHub Discussions](https://github.com/your-username/energy-forecasting-service/discussions)

---

**âš¡ DÃ©veloppÃ© avec passion pour l'Ã©nergie et l'IA âš¡**

*Ce projet constitue un portfolio complet pour dÃ©montrer vos compÃ©tences en Data Science, MLOps et dÃ©veloppement d'applications ML en production.*
